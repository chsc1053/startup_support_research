{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK based Keyword Clustering.\n",
    "This worked well when the no.of clusters to be formed is explicitly mentioned but started to fail when the no.of clusters to be formed are automically decided by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]\n",
    "    filtered_tokens = [token for token in lemmatized_tokens if token not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "def determine_optimal_clusters(keywords):\n",
    "    preprocessed_keywords = [preprocess_text(keyword) for keyword in keywords]\n",
    "    \n",
    "    # Vectorize the preprocessed keywords using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    keyword_vectors = vectorizer.fit_transform(preprocessed_keywords).toarray()\n",
    "    \n",
    "    # Determine the optimal number of clusters using silhouette score\n",
    "    max_clusters = len(keywords) // 2  # Set an upper limit for the number of clusters\n",
    "    optimal_clusters = 2  # Default to 2 clusters\n",
    "    max_silhouette_score = -1\n",
    "    \n",
    "    for num_clusters in range(2, max_clusters + 1):\n",
    "        kmeans_clusterer = KMeansClusterer(num_clusters, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "        assigned_clusters = kmeans_clusterer.cluster(keyword_vectors, assign_clusters=True)\n",
    "        silhouette_avg = silhouette_score(keyword_vectors, assigned_clusters)\n",
    "        \n",
    "        if silhouette_avg > max_silhouette_score:\n",
    "            max_silhouette_score = silhouette_avg\n",
    "            optimal_clusters = num_clusters\n",
    "    \n",
    "    return optimal_clusters\n",
    "\n",
    "def cluster_keywords(keywords):\n",
    "    optimal_clusters = determine_optimal_clusters(keywords)\n",
    "    preprocessed_keywords = [preprocess_text(keyword) for keyword in keywords]\n",
    "    \n",
    "    # Vectorize the preprocessed keywords using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    keyword_vectors = vectorizer.fit_transform(preprocessed_keywords).toarray()\n",
    "    \n",
    "    # Perform clustering using K-means\n",
    "    kmeans_clusterer = KMeansClusterer(optimal_clusters, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "    assigned_clusters = kmeans_clusterer.cluster(keyword_vectors, assign_clusters=True)\n",
    "    \n",
    "    # Print the clustered keywords\n",
    "    clusters = {}\n",
    "    for keyword, cluster_id in zip(keywords, assigned_clusters):\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(keyword)\n",
    "    \n",
    "    for cluster_id, cluster_keywords in clusters.items():\n",
    "        print(\"Cluster {}: {}\".format(cluster_id, \", \".join(cluster_keywords)))\n",
    "\n",
    "keyword_list = [\"apple\", \"banana\", \"orange\", \"cat\", \"dog\", \"elephant\", \"car\", \"bike\", \"train\"]\n",
    "\n",
    "cluster_keywords(keyword_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
